{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fcc806b-db2d-4ca7-8d34-6763310fab03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n",
      "[07:39:51] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: /root/mambaforge/envs/text-classifier/lib/python3.7/site-packages/dgl/tensoradapter/pytorch/libtensoradapter_pytorch_1.10.0.so: cannot open shared object file: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import gensim\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import discord_notify as dn\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from torch import nn\n",
    "from encoder import DocuEncoder, ClassEncoder, DocumentTokenizer\n",
    "from layer import GCN\n",
    "from classifier import TextClassifier\n",
    "from preprocessor import TaxoDataManager, DocumentManager\n",
    "from gensim.test.utils import datapath\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcba6bc0-9a59-46a0-9f82-05235e1708d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = 'data/'\n",
    "TOKEN_LENGTH = 500\n",
    "CLASS_LENGTH = 768\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "word2vec_model = word2vec.Word2Vec.load(os.path.join(DATA_ROOT, 'pretrained/embedding'))\n",
    "document_tokenizer = DocumentTokenizer(DATA_ROOT, TOKEN_LENGTH)\n",
    "dim = word2vec_model.wv.vector_size\n",
    "gcn = GCN(dim, dim, dim, 2, nn.ReLU())\n",
    "class_encoder = ClassEncoder(gcn, word2vec_model)\n",
    "\n",
    "notifier = dn.Notifier('https://discord.com/api/webhooks/917284193036275712/2Da9DmvQjYugyP8pzvB4AzPMqVEizyVipHYLDPE79ZySU2aPGL3imH-YdcqkiUZxf_ku')\n",
    "\n",
    "def create_dataset(data_name, document_file, token_length, taxo_manager, num_val=None):\n",
    "    elapsed_start = time.time()\n",
    "    training_data_dir = os.path.join(DATA_ROOT, f'training_data/{data_name}/')\n",
    "    training_document_manager = DocumentManager(document_file, training_data_dir, f'{data_name}_train', document_tokenizer.Tokenize, taxo_manager, force_token_reload=True)\n",
    "    training_document_manager.load_tokens()\n",
    "    training_document_manager.load_dicts()\n",
    "\n",
    "    num_classes = len(graph.nodes())\n",
    "    training_document_ids = training_document_manager.get_ids()\n",
    "\n",
    "    for i, document_id in enumerate(training_document_ids, 0):\n",
    "        tokens = torch.tensor(training_document_manager.get_tokens(document_id), dtype=torch.int32)\n",
    "        tokens = torch.reshape(tokens, (-1, 1))\n",
    "        positive, non_negative = training_document_manager.get_output_label(document_id)\n",
    "        output = torch.zeros(num_classes, 1)\n",
    "        mask = torch.ones(num_classes, 1, dtype=torch.int32)\n",
    "\n",
    "        for j in non_negative:\n",
    "            if j in positive:\n",
    "                output[j][0] = 1\n",
    "            else:\n",
    "                mask[j] = 0\n",
    "        input = torch.cat((tokens, mask), 0)\n",
    "        if i==0:\n",
    "            train_x = input\n",
    "            train_y = output\n",
    "        else:\n",
    "            train_x = torch.cat((train_x, input), 0)\n",
    "            train_y = torch.cat((train_y, output), 0)\n",
    "        \n",
    "    train_x = torch.reshape(train_x, (-1, num_classes + token_length))\n",
    "    train_y = torch.reshape(train_y, (-1, num_classes, 1))\n",
    "\n",
    "    dataset = TensorDataset(train_x, train_y)\n",
    "    num_dataset = len(dataset)\n",
    "\n",
    "    if num_val is not None:\n",
    "        dataset = random_split(dataset, [num_val, num_dataset - num_val])\n",
    "    \n",
    "    notifier.send(f'{num_dataset}개 데이터셋 생성 완료. 걸린 시간: {round(time.time() - elapsed_start, 2)}.')\n",
    "    \n",
    "    return dataset\n",
    "    \n",
    "    \n",
    "\n",
    "def train_coreclass_epoch(text_classifier, train_dataloader, loss_function, optimizer):\n",
    "    train_loss = 0.0\n",
    "    optimizer.zero_grad()\n",
    "    for i, train_data in enumerate(train_dataloader):\n",
    "        inputs, outputs = train_data\n",
    "        predicted = text_classifier(inputs.cuda())\n",
    "        loss = loss_function(predicted, outputs.cuda())\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        if (i+1) % 8 == 0 :\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "    return train_loss / len(train_dataloader)\n",
    "\n",
    "def validate_coreclass_epoch(model, dataloader, criterion):\n",
    "    valid_loss = 0.0\n",
    "    for data, labels in dataloader:\n",
    "        if torch.cuda.is_available():\n",
    "            data, labels = data.cuda(), labels.cuda()\n",
    "        \n",
    "        target = model(data)\n",
    "        loss = criterion(target,labels)\n",
    "        valid_loss += loss.item()\n",
    "        \n",
    "    return valid_loss / len(dataloader)\n",
    "\n",
    "def print_epoch_result(index, train_loss, val_loss, elapsed_time):\n",
    "    print(f'[{index + 1}]\\ttrain loss: {round(train_loss, 3)}\\tvalidation_loss: {round(valid_loss, 3)}\\telapsed time: {time.time() - start}')\n",
    "\n",
    "def train_coreclass(text_classifier, epoch, train_dataloader, loss_function, optimizer, valid_dataloader, save_path):\n",
    "    train_start = time.time()\n",
    "    text_classifier.cuda()\n",
    "    min_valid_loss = np.inf\n",
    "    \n",
    "    for e in range(epoch):\n",
    "        epoch_start = time.time()\n",
    "        train_loss = train_coreclass_epoch(text_classifier, train_dataloader, loss_function, optimizer)\n",
    "        valid_loss = validate_coreclass_epoch(text_classifier, valid_dataloader, loss_function)\n",
    "        min_valid_loss = save_alltime_best(text_classifier, valid_loss, min_valid_loss, save_path)\n",
    "\n",
    "        print_epoch_result(e, train_loss, valid_loss, time.time() - epoch_start)\n",
    "\n",
    "    notifier.send(f'{epoch} epoch 코어클래스 학습 완료. 걸린 시간: {round(time.time() - train_start, 2)}.')\n",
    "\n",
    "def save_alltime_best(model, val_loss, min_val_loss, save_path):\n",
    "    if min_val_loss > val_loss:\n",
    "        print('Validation loss decreased. Saving the model...')\n",
    "        min_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print('Model saved')\n",
    "\n",
    "    return min_val_loss\n",
    "    \n",
    "def safe_div(a, b, epsilon=1e-8):\n",
    "    return a / b.clamp(min=epsilon)\n",
    "\n",
    "def safe_log(a, epsilon=1e-8):\n",
    "    return torch.log(a.clamp(min=epsilon))\n",
    "\n",
    "def target_distribution(prediction):\n",
    "    weight = safe_div(prediction ** 2, prediction.sum(axis=0))\n",
    "    weight_1 = safe_div((1 - prediction) **2, (1 - prediction).sum(axis=0))\n",
    "    return safe_div(weight, (weight + weight_1))\n",
    "\n",
    "def validate_self(model, dataloader, criterion):\n",
    "    valid_loss = 0.0\n",
    "    for data, _ in dataloader:\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "        \n",
    "        predicted = model(data)\n",
    "        target = target_distribution(predicted) \n",
    "        loss = criterion(predicted, target)\n",
    "        valid_loss += loss.item()\n",
    "        \n",
    "    return valid_loss / len(dataloader)\n",
    "\n",
    "def train_self_epoch(model, train_dataloader, loss_function, optimizer, update_period):\n",
    "    train_loss = 0.0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for i, train_data in enumerate(train_dataloader):\n",
    "        inputs, _ = train_data\n",
    "        predicted = text_classifier(inputs.cuda())\n",
    "        target = target_distribution(predicted)\n",
    "        loss = loss_function(predicted, target)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        if i % update_period == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "    return train_loss / len(train_dataloader)\n",
    "\n",
    "def kl_div_loss(predicted, target):\n",
    "    return (target * safe_log(safe_div(target, predicted))).sum()\n",
    "\n",
    "def train_self(text_classifier, epoch, train_dataloader, loss_function, optimizer, update_period, valid_dataloader, save_path):\n",
    "    text_classifier.cuda()\n",
    "    train_start = time.time()\n",
    "    min_valid_loss = np.inf\n",
    "    \n",
    "    for e in range(epoch): \n",
    "        epoch_start = time.time()\n",
    "\n",
    "        train_loss = train_self_epoch(text_classifier, train_dataloader, loss_function, optimizer, update_period)\n",
    "        valid_loss = validate_self(text_classifier, valid_dataloader, loss_function)\n",
    "        min_valid_loss = save_alltime_best(text_classifier, valid_loss, min_valid_loss, save_path)\n",
    "\n",
    "        print_epoch_result(e, train_loss, valid_loss, time.time() - epoch_start)\n",
    "        \n",
    "    notifier.send(f'{epoch} epoch 자기 학습 완료. 걸린 시간: {round(time.time() - train_start, 2)}.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5122aa0b-c7ef-44ff-b364-57065c3e30ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(data_name, data_filename, num_val, self_training=True):\n",
    "  taxo_manager = TaxoDataManager(os.path.join(DATA_ROOT, f'training_data/{data_name}/'), 'taxonomy.json', data_name, word2vec_model, force_reload=True)\n",
    "  taxo_manager.load_all()\n",
    "  graph = taxo_manager.get_graph().to('cuda:0')\n",
    "  features = taxo_manager.get_feature().cuda()\n",
    "\n",
    "  val_dataset, train_dataset = create_dataset(data_name, data_filename, TOKEN_LENGTH, taxo_manager, num_val)\n",
    "  val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "  train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "  text_classifier = TextClassifier(class_encoder, DocuEncoder(DATA_ROOT), (dim, CLASS_LENGTH), TOKEN_LENGTH, graph, features, nn.Sigmoid(), False)\n",
    "\n",
    "  optimizer = optim.AdamW([\n",
    "    {'params': text_classifier.document_encoder.parameters(), 'lr': 5e-5},\n",
    "    {'params': text_classifier.class_encoder.parameters()},\n",
    "    {'params': text_classifier.weight}], lr=4e-3)\n",
    "\n",
    "  save_path = os.path.join(DATA_ROOT, f'trained/text-classifier-{data_name}.pt')\n",
    "  train_coreclass(text_classifier, 20, train_dataloader, torch.nn.BCELoss(reduction='sum'), optimizer, val_dataloader, save_path)\n",
    "  if self_training:\n",
    "    train_self(text_classifier, 5, train_dataloader, kl_div_loss, optimizer, 25, val_dataloader, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05971dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline('amazon', 'amazon-coreclass-45000.jsonl', 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3320afcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170 words not in the training set!\n",
      "Label dictionary is loaded\n",
      "Calculating tokens from document...\n",
      "Agent\n",
      "{'Agent': [1], 'Device': [2], 'Event': [3], 'Place': [4], 'Species': [5], 'Sports Season': [6], 'Topical Concept': [7], 'Unit Of Work': [8], 'Work': [9], 'Actor': [10], 'Artist': [11], 'Athlete': [12], 'Boxer': [13], 'British Royalty': [14], 'Broadcaster': [15], 'Cleric': [16], 'Coach': [17], 'Comics Character': [18], 'Company': [19], 'Educational Institution': [20], 'Fictional Character': [21], 'Gridiron Football Player': [22], 'Group': [23], 'Motorcycle Rider': [24], 'Musical Artist': [25], 'Organisation': [26], 'Organisation Member': [27], 'Person': [28], 'Politician': [29], 'Presenter': [30], 'Racing Driver': [31], 'Scientist': [32], 'Sports League': [33], 'Sports Manager': [34], 'Sports Team': [35], 'Volleyball Player': [36], 'Winter Sport Player': [37], 'Wrestler': [38], 'Writer': [39], 'Engine': [40], 'Natural Event': [41], 'Olympics': [42], 'Race': [43], 'Societal Event': [44], 'Sports Event': [45], 'Tournament': [46], 'Amusement Park Attraction': [47], 'Body Of Water': [48], 'Building': [49], 'Celestial Body': [50], 'Clerical Administrative Region': [51], 'Infrastructure': [52], 'Natural Place': [53], 'Race Track': [54], 'Route Of Transportation': [55], 'Satellite': [56], 'Settlement': [57], 'Sport Facility': [58], 'Station': [59], 'Stream': [60], 'Tower': [61], 'Venue': [62], 'Animal': [63], 'Eukaryote': [64], 'Flowering Plant': [65], 'Horse': [66], 'Plant': [67], 'Football League Season': [68], 'Sports Team Season': [69], 'Genre': [70], 'Legal Case': [71], 'Cartoon': [72], 'Comic': [73], 'Database': [74], 'Musical Work': [75], 'Periodical Literature': [76], 'Software': [77], 'Song': [78], 'Written Work': [79], 'Adult Actor': [80], 'Voice Actor': [81], 'Comedian': [82], 'Comics Creator': [83], 'Fashion Designer': [84], 'Painter': [85], 'Photographer': [86], 'Australian Rules Football Player': [87], 'Badminton Player': [88], 'Baseball Player': [89], 'Basketball Player': [90], 'Bodybuilder': [91], 'Canoeist': [92], 'Chess Player': [93], 'Cricketer': [94], 'Cyclist': [95], 'Darts Player': [96], 'Gaelic Games Player': [97], 'Golf Player': [98], 'Gymnast': [99], 'Handball Player': [100], 'Horse Rider': [101], 'Jockey': [102], 'Lacrosse Player': [103], 'Martial Artist': [104], 'Netball Player': [105], 'Poker Player': [106], 'Rower': [107], 'Rugby Player': [108], 'Soccer Player': [109], 'Squash Player': [110], 'Swimmer': [111], 'Table Tennis Player': [112], 'Tennis Player': [113], 'Amateur Boxer': [114], 'Baronet': [115], 'Broadcast Network': [116], 'Radio Station': [117], 'Television Station': [118], 'Cardinal': [119], 'Christian Bishop': [120], 'Pope': [121], 'Saint': [122], 'College Coach': [123], 'Animanga Character': [124], 'Airline': [125], 'Bank': [126], 'Brewery': [127], 'Bus Company': [128], 'Law Firm': [129], 'Publisher': [130], 'Record Label': [131], 'Winery': [132], 'Library': [133], 'School': [134], 'University': [135], 'Mythological Figure': [136], 'Soap Character': [137], 'American Football Player': [138], 'Band': [139], 'Speedway Rider': [140], 'Classical Music Artist': [141], 'Legislature': [142], 'Military Unit': [143], 'Political Party': [144], 'Public Transit System': [145], 'Trade Union': [146], 'Sports Team Member': [147], 'Ambassador': [148], 'Architect': [149], 'Astronaut': [150], 'Beauty Queen': [151], 'Business Person': [152], 'Chef': [153], 'Economist': [154], 'Engineer': [155], 'Horse Trainer': [156], 'Journalist': [157], 'Judge': [158], 'Military Person': [159], 'Model': [160], 'Monarch': [161], 'Noble': [162], 'Office Holder': [163], 'Philosopher': [164], 'Playboy Playmate': [165], 'Religious': [166], 'Congressman': [167], 'Governor': [168], 'Mayor': [169], 'Member Of Parliament': [170], 'President': [171], 'Prime Minister': [172], 'Senator': [173], 'Radio Host': [174], 'Formula One Racer': [175], 'Nascar Driver': [176], 'Entomologist': [177], 'Medician': [178], 'Baseball League': [179], 'Basketball League': [180], 'Ice Hockey League': [181], 'Rugby League': [182], 'Soccer League': [183], 'Soccer Manager': [184], 'Australian Football Team': [185], 'Basketball Team': [186], 'Canadian Football Team': [187], 'Cricket Team': [188], 'Cycling Team': [189], 'Handball Team': [190], 'Hockey Team': [191], 'Rugby Club': [192], 'Beach Volleyball Player': [193], 'Curler': [194], 'Figure Skater': [195], 'Ice Hockey Player': [196], 'Skater': [197], 'Skier': [198], 'Sumo Wrestler': [199], 'Historian': [200], 'Poet': [201], 'Screen Writer': [202], 'Automobile Engine': [203], 'Earthquake': [204], 'Solar Eclipse': [205], 'Olympic Event': [206], 'Cycling Race': [207], 'Horse Race': [208], 'Convention': [209], 'Election': [210], 'Film Festival': [211], 'Military Conflict': [212], 'Music Festival': [213], 'Football Match': [214], 'Grand Prix': [215], 'Mixed Martial Arts Event': [216], 'Wrestling Event': [217], 'Golf Tournament': [218], 'Soccer Tournament': [219], 'Tennis Tournament': [220], 'Womens Tennis Association Tournament': [221], 'Roller Coaster': [222], 'Lake': [223], 'Castle': [224], 'Historic Building': [225], 'Hospital': [226], 'Hotel': [227], 'Museum': [228], 'Prison': [229], 'Restaurant': [230], 'Shopping Mall': [231], 'Galaxy': [232], 'Planet': [233], 'Diocese': [234], 'Airport': [235], 'Dam': [236], 'Cave': [237], 'Glacier': [238], 'Mountain': [239], 'Mountain Pass': [240], 'Mountain Range': [241], 'Volcano': [242], 'Racecourse': [243], 'Bridge': [244], 'Railway Line': [245], 'Road': [246], 'Road Tunnel': [247], 'Artificial Satellite': [248], 'Town': [249], 'Village': [250], 'Cricket Ground': [251], 'Golf Course': [252], 'Stadium': [253], 'Railway Station': [254], 'Canal': [255], 'River': [256], 'Lighthouse': [257], 'Theatre': [258], 'Amphibian': [259], 'Arachnid': [260], 'Bird': [261], 'Crustacean': [262], 'Fish': [263], 'Insect': [264], 'Mollusca': [265], 'Reptile': [266], 'Fungus': [267], 'Grape': [268], 'Race Horse': [269], 'Conifer': [270], 'Cultivated Variety': [271], 'Cycad': [272], 'Fern': [273], 'Green Alga': [274], 'Moss': [275], 'National Football League Season': [276], 'Baseball Season': [277], 'Ncaa Team Season': [278], 'Soccer Club Season': [279], 'Music Genre': [280], 'Supreme Court Of The United States Case': [281], 'Anime': [282], 'Hollywood Cartoon': [283], 'Comic Strip': [284], 'Manga': [285], 'Biological Database': [286], 'Album': [287], 'Artist Discography': [288], 'Classical Music Composition': [289], 'Musical': [290], 'Single': [291], 'Academic Journal': [292], 'Magazine': [293], 'Newspaper': [294], 'Video Game': [295], 'Eurovision Song Contest Entry': [296], 'Play': [297], 'Poem': [298]}\n",
      "Actor\n",
      "{'Agent': [1], 'Device': [2], 'Event': [3], 'Place': [4], 'Species': [5], 'Sports Season': [6], 'Topical Concept': [7], 'Unit Of Work': [8], 'Work': [9], 'Actor': [10], 'Artist': [11], 'Athlete': [12], 'Boxer': [13], 'British Royalty': [14], 'Broadcaster': [15], 'Cleric': [16], 'Coach': [17], 'Comics Character': [18], 'Company': [19], 'Educational Institution': [20], 'Fictional Character': [21], 'Gridiron Football Player': [22], 'Group': [23], 'Motorcycle Rider': [24], 'Musical Artist': [25], 'Organisation': [26], 'Organisation Member': [27], 'Person': [28], 'Politician': [29], 'Presenter': [30], 'Racing Driver': [31], 'Scientist': [32], 'Sports League': [33], 'Sports Manager': [34], 'Sports Team': [35], 'Volleyball Player': [36], 'Winter Sport Player': [37], 'Wrestler': [38], 'Writer': [39], 'Engine': [40], 'Natural Event': [41], 'Olympics': [42], 'Race': [43], 'Societal Event': [44], 'Sports Event': [45], 'Tournament': [46], 'Amusement Park Attraction': [47], 'Body Of Water': [48], 'Building': [49], 'Celestial Body': [50], 'Clerical Administrative Region': [51], 'Infrastructure': [52], 'Natural Place': [53], 'Race Track': [54], 'Route Of Transportation': [55], 'Satellite': [56], 'Settlement': [57], 'Sport Facility': [58], 'Station': [59], 'Stream': [60], 'Tower': [61], 'Venue': [62], 'Animal': [63], 'Eukaryote': [64], 'Flowering Plant': [65], 'Horse': [66], 'Plant': [67], 'Football League Season': [68], 'Sports Team Season': [69], 'Genre': [70], 'Legal Case': [71], 'Cartoon': [72], 'Comic': [73], 'Database': [74], 'Musical Work': [75], 'Periodical Literature': [76], 'Software': [77], 'Song': [78], 'Written Work': [79], 'Adult Actor': [80], 'Voice Actor': [81], 'Comedian': [82], 'Comics Creator': [83], 'Fashion Designer': [84], 'Painter': [85], 'Photographer': [86], 'Australian Rules Football Player': [87], 'Badminton Player': [88], 'Baseball Player': [89], 'Basketball Player': [90], 'Bodybuilder': [91], 'Canoeist': [92], 'Chess Player': [93], 'Cricketer': [94], 'Cyclist': [95], 'Darts Player': [96], 'Gaelic Games Player': [97], 'Golf Player': [98], 'Gymnast': [99], 'Handball Player': [100], 'Horse Rider': [101], 'Jockey': [102], 'Lacrosse Player': [103], 'Martial Artist': [104], 'Netball Player': [105], 'Poker Player': [106], 'Rower': [107], 'Rugby Player': [108], 'Soccer Player': [109], 'Squash Player': [110], 'Swimmer': [111], 'Table Tennis Player': [112], 'Tennis Player': [113], 'Amateur Boxer': [114], 'Baronet': [115], 'Broadcast Network': [116], 'Radio Station': [117], 'Television Station': [118], 'Cardinal': [119], 'Christian Bishop': [120], 'Pope': [121], 'Saint': [122], 'College Coach': [123], 'Animanga Character': [124], 'Airline': [125], 'Bank': [126], 'Brewery': [127], 'Bus Company': [128], 'Law Firm': [129], 'Publisher': [130], 'Record Label': [131], 'Winery': [132], 'Library': [133], 'School': [134], 'University': [135], 'Mythological Figure': [136], 'Soap Character': [137], 'American Football Player': [138], 'Band': [139], 'Speedway Rider': [140], 'Classical Music Artist': [141], 'Legislature': [142], 'Military Unit': [143], 'Political Party': [144], 'Public Transit System': [145], 'Trade Union': [146], 'Sports Team Member': [147], 'Ambassador': [148], 'Architect': [149], 'Astronaut': [150], 'Beauty Queen': [151], 'Business Person': [152], 'Chef': [153], 'Economist': [154], 'Engineer': [155], 'Horse Trainer': [156], 'Journalist': [157], 'Judge': [158], 'Military Person': [159], 'Model': [160], 'Monarch': [161], 'Noble': [162], 'Office Holder': [163], 'Philosopher': [164], 'Playboy Playmate': [165], 'Religious': [166], 'Congressman': [167], 'Governor': [168], 'Mayor': [169], 'Member Of Parliament': [170], 'President': [171], 'Prime Minister': [172], 'Senator': [173], 'Radio Host': [174], 'Formula One Racer': [175], 'Nascar Driver': [176], 'Entomologist': [177], 'Medician': [178], 'Baseball League': [179], 'Basketball League': [180], 'Ice Hockey League': [181], 'Rugby League': [182], 'Soccer League': [183], 'Soccer Manager': [184], 'Australian Football Team': [185], 'Basketball Team': [186], 'Canadian Football Team': [187], 'Cricket Team': [188], 'Cycling Team': [189], 'Handball Team': [190], 'Hockey Team': [191], 'Rugby Club': [192], 'Beach Volleyball Player': [193], 'Curler': [194], 'Figure Skater': [195], 'Ice Hockey Player': [196], 'Skater': [197], 'Skier': [198], 'Sumo Wrestler': [199], 'Historian': [200], 'Poet': [201], 'Screen Writer': [202], 'Automobile Engine': [203], 'Earthquake': [204], 'Solar Eclipse': [205], 'Olympic Event': [206], 'Cycling Race': [207], 'Horse Race': [208], 'Convention': [209], 'Election': [210], 'Film Festival': [211], 'Military Conflict': [212], 'Music Festival': [213], 'Football Match': [214], 'Grand Prix': [215], 'Mixed Martial Arts Event': [216], 'Wrestling Event': [217], 'Golf Tournament': [218], 'Soccer Tournament': [219], 'Tennis Tournament': [220], 'Womens Tennis Association Tournament': [221], 'Roller Coaster': [222], 'Lake': [223], 'Castle': [224], 'Historic Building': [225], 'Hospital': [226], 'Hotel': [227], 'Museum': [228], 'Prison': [229], 'Restaurant': [230], 'Shopping Mall': [231], 'Galaxy': [232], 'Planet': [233], 'Diocese': [234], 'Airport': [235], 'Dam': [236], 'Cave': [237], 'Glacier': [238], 'Mountain': [239], 'Mountain Pass': [240], 'Mountain Range': [241], 'Volcano': [242], 'Racecourse': [243], 'Bridge': [244], 'Railway Line': [245], 'Road': [246], 'Road Tunnel': [247], 'Artificial Satellite': [248], 'Town': [249], 'Village': [250], 'Cricket Ground': [251], 'Golf Course': [252], 'Stadium': [253], 'Railway Station': [254], 'Canal': [255], 'River': [256], 'Lighthouse': [257], 'Theatre': [258], 'Amphibian': [259], 'Arachnid': [260], 'Bird': [261], 'Crustacean': [262], 'Fish': [263], 'Insect': [264], 'Mollusca': [265], 'Reptile': [266], 'Fungus': [267], 'Grape': [268], 'Race Horse': [269], 'Conifer': [270], 'Cultivated Variety': [271], 'Cycad': [272], 'Fern': [273], 'Green Alga': [274], 'Moss': [275], 'National Football League Season': [276], 'Baseball Season': [277], 'Ncaa Team Season': [278], 'Soccer Club Season': [279], 'Music Genre': [280], 'Supreme Court Of The United States Case': [281], 'Anime': [282], 'Hollywood Cartoon': [283], 'Comic Strip': [284], 'Manga': [285], 'Biological Database': [286], 'Album': [287], 'Artist Discography': [288], 'Classical Music Composition': [289], 'Musical': [290], 'Single': [291], 'Academic Journal': [292], 'Magazine': [293], 'Newspaper': [294], 'Video Game': [295], 'Eurovision Song Contest Entry': [296], 'Play': [297], 'Poem': [298]}\n",
      "AdultActor\n",
      "{'Agent': [1], 'Device': [2], 'Event': [3], 'Place': [4], 'Species': [5], 'Sports Season': [6], 'Topical Concept': [7], 'Unit Of Work': [8], 'Work': [9], 'Actor': [10], 'Artist': [11], 'Athlete': [12], 'Boxer': [13], 'British Royalty': [14], 'Broadcaster': [15], 'Cleric': [16], 'Coach': [17], 'Comics Character': [18], 'Company': [19], 'Educational Institution': [20], 'Fictional Character': [21], 'Gridiron Football Player': [22], 'Group': [23], 'Motorcycle Rider': [24], 'Musical Artist': [25], 'Organisation': [26], 'Organisation Member': [27], 'Person': [28], 'Politician': [29], 'Presenter': [30], 'Racing Driver': [31], 'Scientist': [32], 'Sports League': [33], 'Sports Manager': [34], 'Sports Team': [35], 'Volleyball Player': [36], 'Winter Sport Player': [37], 'Wrestler': [38], 'Writer': [39], 'Engine': [40], 'Natural Event': [41], 'Olympics': [42], 'Race': [43], 'Societal Event': [44], 'Sports Event': [45], 'Tournament': [46], 'Amusement Park Attraction': [47], 'Body Of Water': [48], 'Building': [49], 'Celestial Body': [50], 'Clerical Administrative Region': [51], 'Infrastructure': [52], 'Natural Place': [53], 'Race Track': [54], 'Route Of Transportation': [55], 'Satellite': [56], 'Settlement': [57], 'Sport Facility': [58], 'Station': [59], 'Stream': [60], 'Tower': [61], 'Venue': [62], 'Animal': [63], 'Eukaryote': [64], 'Flowering Plant': [65], 'Horse': [66], 'Plant': [67], 'Football League Season': [68], 'Sports Team Season': [69], 'Genre': [70], 'Legal Case': [71], 'Cartoon': [72], 'Comic': [73], 'Database': [74], 'Musical Work': [75], 'Periodical Literature': [76], 'Software': [77], 'Song': [78], 'Written Work': [79], 'Adult Actor': [80], 'Voice Actor': [81], 'Comedian': [82], 'Comics Creator': [83], 'Fashion Designer': [84], 'Painter': [85], 'Photographer': [86], 'Australian Rules Football Player': [87], 'Badminton Player': [88], 'Baseball Player': [89], 'Basketball Player': [90], 'Bodybuilder': [91], 'Canoeist': [92], 'Chess Player': [93], 'Cricketer': [94], 'Cyclist': [95], 'Darts Player': [96], 'Gaelic Games Player': [97], 'Golf Player': [98], 'Gymnast': [99], 'Handball Player': [100], 'Horse Rider': [101], 'Jockey': [102], 'Lacrosse Player': [103], 'Martial Artist': [104], 'Netball Player': [105], 'Poker Player': [106], 'Rower': [107], 'Rugby Player': [108], 'Soccer Player': [109], 'Squash Player': [110], 'Swimmer': [111], 'Table Tennis Player': [112], 'Tennis Player': [113], 'Amateur Boxer': [114], 'Baronet': [115], 'Broadcast Network': [116], 'Radio Station': [117], 'Television Station': [118], 'Cardinal': [119], 'Christian Bishop': [120], 'Pope': [121], 'Saint': [122], 'College Coach': [123], 'Animanga Character': [124], 'Airline': [125], 'Bank': [126], 'Brewery': [127], 'Bus Company': [128], 'Law Firm': [129], 'Publisher': [130], 'Record Label': [131], 'Winery': [132], 'Library': [133], 'School': [134], 'University': [135], 'Mythological Figure': [136], 'Soap Character': [137], 'American Football Player': [138], 'Band': [139], 'Speedway Rider': [140], 'Classical Music Artist': [141], 'Legislature': [142], 'Military Unit': [143], 'Political Party': [144], 'Public Transit System': [145], 'Trade Union': [146], 'Sports Team Member': [147], 'Ambassador': [148], 'Architect': [149], 'Astronaut': [150], 'Beauty Queen': [151], 'Business Person': [152], 'Chef': [153], 'Economist': [154], 'Engineer': [155], 'Horse Trainer': [156], 'Journalist': [157], 'Judge': [158], 'Military Person': [159], 'Model': [160], 'Monarch': [161], 'Noble': [162], 'Office Holder': [163], 'Philosopher': [164], 'Playboy Playmate': [165], 'Religious': [166], 'Congressman': [167], 'Governor': [168], 'Mayor': [169], 'Member Of Parliament': [170], 'President': [171], 'Prime Minister': [172], 'Senator': [173], 'Radio Host': [174], 'Formula One Racer': [175], 'Nascar Driver': [176], 'Entomologist': [177], 'Medician': [178], 'Baseball League': [179], 'Basketball League': [180], 'Ice Hockey League': [181], 'Rugby League': [182], 'Soccer League': [183], 'Soccer Manager': [184], 'Australian Football Team': [185], 'Basketball Team': [186], 'Canadian Football Team': [187], 'Cricket Team': [188], 'Cycling Team': [189], 'Handball Team': [190], 'Hockey Team': [191], 'Rugby Club': [192], 'Beach Volleyball Player': [193], 'Curler': [194], 'Figure Skater': [195], 'Ice Hockey Player': [196], 'Skater': [197], 'Skier': [198], 'Sumo Wrestler': [199], 'Historian': [200], 'Poet': [201], 'Screen Writer': [202], 'Automobile Engine': [203], 'Earthquake': [204], 'Solar Eclipse': [205], 'Olympic Event': [206], 'Cycling Race': [207], 'Horse Race': [208], 'Convention': [209], 'Election': [210], 'Film Festival': [211], 'Military Conflict': [212], 'Music Festival': [213], 'Football Match': [214], 'Grand Prix': [215], 'Mixed Martial Arts Event': [216], 'Wrestling Event': [217], 'Golf Tournament': [218], 'Soccer Tournament': [219], 'Tennis Tournament': [220], 'Womens Tennis Association Tournament': [221], 'Roller Coaster': [222], 'Lake': [223], 'Castle': [224], 'Historic Building': [225], 'Hospital': [226], 'Hotel': [227], 'Museum': [228], 'Prison': [229], 'Restaurant': [230], 'Shopping Mall': [231], 'Galaxy': [232], 'Planet': [233], 'Diocese': [234], 'Airport': [235], 'Dam': [236], 'Cave': [237], 'Glacier': [238], 'Mountain': [239], 'Mountain Pass': [240], 'Mountain Range': [241], 'Volcano': [242], 'Racecourse': [243], 'Bridge': [244], 'Railway Line': [245], 'Road': [246], 'Road Tunnel': [247], 'Artificial Satellite': [248], 'Town': [249], 'Village': [250], 'Cricket Ground': [251], 'Golf Course': [252], 'Stadium': [253], 'Railway Station': [254], 'Canal': [255], 'River': [256], 'Lighthouse': [257], 'Theatre': [258], 'Amphibian': [259], 'Arachnid': [260], 'Bird': [261], 'Crustacean': [262], 'Fish': [263], 'Insect': [264], 'Mollusca': [265], 'Reptile': [266], 'Fungus': [267], 'Grape': [268], 'Race Horse': [269], 'Conifer': [270], 'Cultivated Variety': [271], 'Cycad': [272], 'Fern': [273], 'Green Alga': [274], 'Moss': [275], 'National Football League Season': [276], 'Baseball Season': [277], 'Ncaa Team Season': [278], 'Soccer Club Season': [279], 'Music Genre': [280], 'Supreme Court Of The United States Case': [281], 'Anime': [282], 'Hollywood Cartoon': [283], 'Comic Strip': [284], 'Manga': [285], 'Biological Database': [286], 'Album': [287], 'Artist Discography': [288], 'Classical Music Composition': [289], 'Musical': [290], 'Single': [291], 'Academic Journal': [292], 'Magazine': [293], 'Newspaper': [294], 'Video Game': [295], 'Eurovision Song Contest Entry': [296], 'Play': [297], 'Poem': [298]}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15253/2134329971.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DBPEDIA'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'DBPEDIA-coreclass-45000.jsonl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_15253/4056355853.py\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(data_name, data_filename, num_val, self_training)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtaxo_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTOKEN_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtaxo_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mval_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mtrain_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_15253/2968751619.py\u001b[0m in \u001b[0;36mcreate_dataset\u001b[0;34m(data_name, document_file, token_length, taxo_manager, num_val)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mtraining_data_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_ROOT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'training_data/{data_name}/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mtraining_document_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDocumentManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_data_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{data_name}_train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTokenize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtaxo_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_token_reload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mtraining_document_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mtraining_document_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_dicts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/TaxoReplica/text-classifier/preprocessor.py\u001b[0m in \u001b[0;36mload_tokens\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforce_token_reload\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Calculating tokens from document...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Calculation is finished!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/TaxoReplica/text-classifier/preprocessor.py\u001b[0m in \u001b[0;36mload_from_raw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    332\u001b[0m               \u001b[0mchilds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtaxo_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild_from_parent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m               \u001b[0mlabel_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtaxo_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid_from_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m               \u001b[0mlabel_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchilds\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m               \u001b[0mparent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "pipeline('DBPEDIA', 'DBPEDIA-coreclass-45000.jsonl', 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a29316-1c69-4611-8b0e-b18bac30f7b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:text-classifier] *",
   "language": "python",
   "name": "conda-env-text-classifier-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
